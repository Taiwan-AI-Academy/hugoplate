---
title: "Meta新一代影像理解模型"
description: "視覺場景中尋找並分割任何物體的能力，是多模態人工智慧的基礎要素。"
date: 2025-11-30T10:01:43+08:00
image: "/images/sam3-concept.jpg"
categories: ["AI", "Computer Vision"]
author: "Meta"
tags: ["多模態", "影像理解"]
draft: false
slug: "meta-new-image-understanding-model"
---

視覺場景中尋找並分割任何物體的能力，是多模態人工智慧的基礎要素。SAM 3 讓這項能力從「單一物體」跨越到「概念級」的偵測與追蹤。

## 從 PVS 到 PCS
- 過去 SAM 系列專注於提示式視覺分割（PVS），透過點、框或遮罩提示分割單一物體。
- SAM 3 聚焦「提示式概念分割」（PCS），目標是偵測、分割並追蹤圖像與影片中所有符合概念提示的實例。
- 概念提示可為簡短名詞詞組（例：「黃色校車」）、圖像範例，或兩者的組合。

SAM 3 就像為視覺人工智慧配備了一位專業的「概念狩獵者」：能依簡短描述鎖定並追蹤所有符合概念的目標，不論是靜態圖像或動態影片。

## 數據引擎：規模與品質
- 建構可擴展的數據引擎，並將辨識與定位解耦，解決開放詞彙概念偵測的挑戰。
- 結合人類標註者與 AI Verifiers，產出大規模高品質訓練集：四百萬個獨特短名詞概念標籤、五千兩百萬個遮罩。

![SAM 3 數據引擎流程](/images/sam3-data-engine.jpg)

## 模型架構：解耦辨識與定位
- 圖像層級偵測器 + 基於記憶體的影片追蹤器，共享單一骨幹。
- 偵測器加入獨立的「存在標記」（Presence Head），專責判斷目標概念是否存在，與定位分離以提升準確性。

![SAM 3 架構示意](/images/sam3-concept.jpg)

## 實驗表現
- 在圖像與影片的 PCS 任務上，準確度較現有系統提升逾一倍。
- Segment Anything with Concepts (SA-Co) 基準全面領先；LVIS 資料集 zero-shot 遮罩 AP 48.8（前一最佳 38.5）。
- 這項成果為機器人、內容創作、擴增實境等應用奠定更堅實的基礎。
